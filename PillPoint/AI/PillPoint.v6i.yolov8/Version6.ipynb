{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train path: True\n",
      "Validation path: True\n",
      "Test path: True\n",
      " The number of images in training set: 2969\n",
      " The number of images in validation set: 251\n",
      " The number of images in test set: 116\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "with open('data.yaml', 'r') as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "print(\"Train path:\", os.path.exists(data['train']))\n",
    "print(\"Validation path:\", os.path.exists(data['val']))\n",
    "print(\"Test path:\", os.path.exists(data['test']))\n",
    "\n",
    "def count_images(directory):\n",
    "    supported_formats = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif')\n",
    "    return len([name for name in os.listdir(directory) if name.lower().endswith(supported_formats)])\n",
    "\n",
    "print(f\" The number of images in training set: {count_images(data['train'])}\")\n",
    "print(f\" The number of images in validation set: {count_images(data['val'])}\")\n",
    "print(f\" The number of images in test set: {count_images(data['test'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "\n",
    "absolute_from_relative_path = Path('data.yaml').resolve()\n",
    "\n",
    "model = YOLO('yolov8n.pt')  # Load a pretrained model (recommended for training)\n",
    "results = model.train(data=absolute_from_relative_path, epochs=20, imgsz=480)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # OpenCV library for computer vision tasks\n",
    "from ultralytics import YOLO  # YOLO model for object detection\n",
    "from PIL import Image, ImageTk  # PIL for image processing and integration with Tkinter\n",
    "import tkinter as tk  # Tkinter for GUI\n",
    "import socket  # Socket for network communication\n",
    "import threading  # Threading for concurrent operations\n",
    "import time  # Time for handling time-related operations\n",
    "\n",
    "# Load the trained YOLOv8 model\n",
    "try:\n",
    "    model = YOLO('runs/detect/train/weights/best.pt')\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Define the class names\n",
    "class_names = ['FRI-am', 'FRI-pm', 'Hands', 'MON-am', 'MON-pm', 'Open', 'Pill', 'PillBox', 'SAT-am', 'SAT-pm', 'SUN-am', 'SUN-pm', 'THU-am', 'THU-pm', 'TUE-am', 'TUE-pm', 'WED-am', 'WED-pm']\n",
    "\n",
    "# Define colors for each class visualization\n",
    "class_colors = {\n",
    "    'FRI-am': (0, 255, 255),\n",
    "    'FRI-pm': (255, 255, 0),\n",
    "    'Hands': (0, 255, 0),\n",
    "    'MON-am': (255, 0, 255),\n",
    "    'MON-pm': (0, 255, 255),\n",
    "    'Open': (255, 255, 0),\n",
    "    'Pill': (255, 0, 0),\n",
    "    'PillBox': (0, 255, 255),\n",
    "    'SAT-am': (255, 165, 0),\n",
    "    'SAT-pm': (255, 69, 0),\n",
    "    'SUN-am': (128, 0, 128),\n",
    "    'SUN-pm': (75, 0, 130),\n",
    "    'THU-am': (0, 255, 255),\n",
    "    'THU-pm': (0, 128, 128),\n",
    "    'TUE-am': (255, 0, 255),\n",
    "    'TUE-pm': (128, 0, 0),\n",
    "    'WED-am': (0, 0, 255),\n",
    "    'WED-pm': (0, 128, 0)\n",
    "}\n",
    "\n",
    "# Server address and port for Raspberry Pi\n",
    "server_address = ('192.168.168.167', 1443)  # Change this to your Raspberry Pi IP and port\n",
    "\n",
    "# Global vars for use in methods/threads\n",
    "client_socket = None\n",
    "receive_thread = None\n",
    "shutdown_flag = threading.Event()\n",
    "last_notification_time = 0\n",
    "notification_interval = 1\n",
    "current_day_time = None\n",
    "\n",
    "def setup_socket_client():\n",
    "    global client_socket, receive_thread\n",
    "    client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)  # Create a socket instance\n",
    "    client_socket.connect(server_address)  # Connect to specified server\n",
    "    print(\"Connected to server\")\n",
    "\n",
    "# Start a thread to handle incoming messages\n",
    "    receive_thread = threading.Thread(target=receive_messages, args=(client_socket, shutdown_flag))\n",
    "    receive_thread.start()\n",
    "\n",
    "def receive_messages(sock, shutdown_flag):\n",
    "    global current_day_time\n",
    "    sock.settimeout(1)  # Set a timeout on the socket so we can check shutdown_flag.is_set in the loop, instead of blocking\n",
    "    try:\n",
    "        while not shutdown_flag.is_set():  # As long as ctrl+c is not pressed\n",
    "            try:\n",
    "                data = sock.recv(1024)  # Try to receive 1024 bytes of data (maximum amount; can be less)\n",
    "                if not data:  # When no data is received, try again (and shutdown flag is checked again)\n",
    "                    break\n",
    "                current_day_time = data.decode()\n",
    "                print(\"Received from server:\", current_day_time)  # Print the received data, or do something with it\n",
    "            except socket.timeout:  # When no data comes within timeout, try again\n",
    "                continue\n",
    "    except Exception as e:\n",
    "        if not shutdown_flag.is_set():\n",
    "            print(f\"Connection error: {e}\")\n",
    "    finally:\n",
    "        sock.close()\n",
    "\n",
    "def request_date_time():\n",
    "    global client_socket\n",
    "    try:\n",
    "        client_socket.sendall(\"Request date and time\".encode())\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to request date and time: {e}\")\n",
    "\n",
    "# Function to draw bounding boxes with different colors\n",
    "def draw_bounding_boxes(image, results): #image, which is the image/frame to be annotated, and results, which is the detection results from the YOLO model.\n",
    "    global last_notification_time, current_day_time #global to indicate that it will modify the global variables \n",
    "    boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "    confs = results[0].boxes.conf.cpu().numpy()\n",
    "    classes = results[0].boxes.cls.cpu().numpy() #It extracts the bounding box coordinates, confidence scores, and class indices from the detection results and converts them to numpy arrays for easier manipulation.\n",
    "    \n",
    "    pillbox_detected = False\n",
    "    compartment_open_detected = False\n",
    "    wrong_compartment_opened = False\n",
    "    \n",
    "\n",
    "    #Iterates over the detected boxes. For each box\n",
    "    for i, box in enumerate(boxes):\n",
    "        x1, y1, x2, y2 = map(int, box) #Extracts the coordinates (x1, y1, x2, y2) and converts them to integers\n",
    "        conf = confs[i]  #Retrieves the confidence score conf and class index cls\n",
    "        cls = int(classes[i])  #Maps the class index to the corresponding class name label.\n",
    "        label = class_names[cls]\n",
    "        \n",
    "        # Get color for the class\n",
    "        color = class_colors.get(label, (0, 0, 255))  # Default to blue if not found\n",
    "        \n",
    "        # Draw bounding box and label\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(image, f'{label} {confs[i]:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "        \n",
    "        # Check if PillBox is detected\n",
    "        if label == 'PillBox':\n",
    "            pillbox_detected = True\n",
    "\n",
    "        # Check if compartment is opened\n",
    "        if label == 'Open':\n",
    "            compartment_open_detected = True\n",
    "            \n",
    "        # Check if the compartment corresponds to the current day and time\n",
    "        if pillbox_detected and compartment_open_detected:\n",
    "            if current_day_time and label not in current_day_time:\n",
    "                wrong_compartment_opened = True\n",
    "            \n",
    "        if wrong_compartment_opened:\n",
    "            # Add logic to trigger buzzer notification\n",
    "            send_buzzer_notification()\n",
    "\n",
    "def send_buzzer_notification():\n",
    "    global client_socket\n",
    "    try:\n",
    "        client_socket.sendall(\"Wrong pill detected\".encode())\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to send buzzer notification: {e}\")\n",
    "\n",
    "# AI part\n",
    "def process_frame(frame):\n",
    "    # Perform inference with the YOLOv8 model\n",
    "    try:\n",
    "        results = model(frame)\n",
    "    except Exception as e:\n",
    "        print(f\"Error performing inference: {e}\")\n",
    "        return frame\n",
    "\n",
    "    # Annotate the frame with detection results\n",
    "    draw_bounding_boxes(frame, results)\n",
    "\n",
    "    return frame\n",
    "\n",
    "# Tkinter GUI part\n",
    "def update_frame():\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert colorspace from BGR to RGB\n",
    "        frame = process_frame(frame) #Calls process_frame(frame) to perform object detection and annotation on the frame.\n",
    "        img = Image.fromarray(frame)  #Converts the processed frame (which is a numpy array) to a PIL Image object using Image.fromarray.\n",
    "        imgtk = ImageTk.PhotoImage(image=img) #Converts the PIL Image to a format suitable for displaying in a Tkinter GUI using ImageTk.PhotoImage.\n",
    "        label_img.imgtk = imgtk #Updates the image displayed in the Tkinter Label widget (label_img) with the new frame by setting its image attribute to imgtk.\n",
    "        label_img.configure(image=imgtk)\n",
    "    else:\n",
    "        print(\"Error reading frame from webcam\")\n",
    "    label_img.after(10, update_frame)  # Schedule the update after 10 milliseconds\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "# Setup Tkinter window\n",
    "window = tk.Tk()\n",
    "window.title(\"Pill Detection\")\n",
    "window.geometry(\"800x600\")\n",
    "\n",
    "# Create a label to display the webcam feed\n",
    "label_img = tk.Label(window)\n",
    "label_img.pack()\n",
    "\n",
    "# Start the socket client\n",
    "setup_socket_client()\n",
    "\n",
    "# Request the initial date and time\n",
    "request_date_time()\n",
    "\n",
    "# Start the webcam feed update\n",
    "update_frame()\n",
    "\n",
    "# Start the Tkinter event loop\n",
    "window.mainloop()\n",
    "\n",
    "# Release the webcam\n",
    "cap.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
